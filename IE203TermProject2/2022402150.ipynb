{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Necessary imports\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import timeit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of files that contains datasets\n",
    "\n",
    "file_names = [\"HW2_2022402150_10.txt\",\n",
    "              \"HW2_2022402150_100.txt\",\n",
    "              \"HW2_2022402150_1000.txt\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculates mean square error of two arrays\n",
    "\n",
    "def mse(base_arr, compare_arr):\n",
    "    return np.sum(np.square(base_arr-compare_arr))/len(base_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Returns array from a dataset in a file\n",
    "\n",
    "def pull_file(file_name):\n",
    "    return np.genfromtxt(file_name, delimiter=\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Returns steady state probabilites by utilizing eigenvalues and eigenvectors\n",
    "\n",
    "def method_analytic_solution(arr):\n",
    "    eigenvalues, eigenvectors = np.linalg.eig(arr.T) # Returns eigenvalues and left eigenvectors\n",
    "    left_eigenvector = eigenvectors[:, np.where(np.isclose(eigenvalues, 1))[0][0]].T # Finds the eigenvector which has the approximate eigenvalue of 1\n",
    "    left_eigenvector /= np.sum(left_eigenvector) # Normalizes that vector\n",
    "    return np.real(left_eigenvector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Returns steady state probabilities by executing a simulation\n",
    "\n",
    "def method_simulation(arr, T=1000000):\n",
    "    count = 0\n",
    "    arr_len = len(arr[0]) # Returns the lenght of a row of the array\n",
    "    realizations = {i:0 for i in range(arr_len)} # Creates a dictionary that has the necessary keys\n",
    "    current_row = arr[np.random.randint(0, arr_len)] # Chooses a random row\n",
    "    while count < T:\n",
    "        r = np.random.random() # Chooses a random number between 0 and 1\n",
    "        for c, entry in enumerate(current_row): # To find which interval consists r in the current row\n",
    "            r -= entry # Decreases r by the entry\n",
    "            if r <= 0: # Where r reaches 0, it is the interval that consists r\n",
    "                break\n",
    "        realizations[c] += 1 # Add visit to realizations\n",
    "        current_row = arr[c] # Go next row\n",
    "        count += 1\n",
    "    return np.array(list(realizations.values()))/T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multiplies the array by itself until its column starts to imitate one another\n",
    "\n",
    "def method_matrix_multiplication(arr, tolerance=0.000001):\n",
    "    arr_len = len(arr[0])\n",
    "    not_done = True\n",
    "    while not_done: # Executes until stop statement is true  \n",
    "        for c in range(arr_len):      \n",
    "            error = False\n",
    "            column = arr[:, c] # Takes the transpose\n",
    "            col_avg = np.sum(column)/arr_len # Finds the average of the transposed column\n",
    "            for entry in column:\n",
    "                if np.abs(entry- col_avg) >= tolerance: # Checks whether the tolerance is violated\n",
    "                    error = True # If any of the values is greater than the tolerance, raises error\n",
    "                    break\n",
    "            if error: # If there is an error, breaks from the loop and starts to next one\n",
    "                break    \n",
    "        else:\n",
    "            not_done = False # If no errors is encountered, then while loop can be broken\n",
    "             \n",
    "        if not_done:         \n",
    "            arr = np.matmul(arr, arr) # If there is an error, multiplies the array by itself to produce the next array for the next loop\n",
    "                  \n",
    "    return arr[0] # Returned row does not matter since all the rows are approxiametly identically same"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Measures the runtimes of each method 10 times and returns their mean\n",
    "\n",
    "def measure_time(arr):\n",
    "    \n",
    "    exe_time_1 = timeit.timeit(lambda: method_analytic_solution(arr), number=10)\n",
    "    exe_time_2 = timeit.timeit(lambda: method_simulation(arr), number=10)\n",
    "    exe_time_3 = timeit.timeit(lambda: method_matrix_multiplication(arr), number=10)\n",
    "    \n",
    "    return exe_time_1, exe_time_2, exe_time_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Returns the final dataframe by using previous declared functions\n",
    "\n",
    "def create_dataframe(file_names):\n",
    "    datasets = {} # Stores the information to create data frame in further steps\n",
    "\n",
    "    for  n, dataset in enumerate(file_names): # Loops over all files\n",
    "        arr = pull_file(dataset) # Creates an array from the current file\n",
    "\n",
    "        # Creates the variables that stores steady states\n",
    "        analytic_sol = method_analytic_solution(arr)\n",
    "        simulation_sol = method_simulation(arr)\n",
    "        multiplication_sol = method_matrix_multiplication(arr)\n",
    "        \n",
    "        # Creates the variables that stores runtimes\n",
    "        runtime_1, runtime_2, runtime_3 = measure_time(arr)\n",
    "\n",
    "        # Creates a dictionary that stores the information of the current array\n",
    "        df_dict = {(f\"Dataset {n+1}\", \"MSE\"): [\"-\", mse(analytic_sol, simulation_sol), mse(analytic_sol, multiplication_sol)],\n",
    "                   (f\"Dataset {n+1}\", \"Runtime (s)\"): [runtime_1, runtime_2, runtime_3]}\n",
    "\n",
    "        # Extends the \"datasets\" dictionary with freshly created dictionary\n",
    "        datasets.update(df_dict)\n",
    "\n",
    "\n",
    "    method_indexes = [\"Method 1\", \"Method 2\", \"Method 3\"] # To index row headers\n",
    "    df = pd.DataFrame(data=datasets) # Creates a dataframe\n",
    "    df.index = method_indexes  # Indexes rows\n",
    "    return df # Returns the final data frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creates an absorbing state for a given array\n",
    "\n",
    "def create_absorbing_state(arr):\n",
    "    arr_len = len(arr[0]) # Finds the lenght of a row of given array\n",
    "    arr[0] = np.array([1] + [0 for i in range(arr_len-1)]) # Changes the first row with 0's except the first entry which is changed with 1\n",
    "    return arr # Returns the new array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For given array with an absorbing state, returns their steady states\n",
    "\n",
    "def check_absorbing_state(arr):\n",
    "    return method_analytic_solution(arr), method_simulation(arr), method_matrix_multiplication(arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Returns step counts that executed in method 3 for each case\n",
    "\n",
    "def number_of_iterations_of_method_3(file_names):\n",
    "    steps = {}\n",
    "    \n",
    "    # Change the function to return step count\n",
    "    def method_matrix_multiplication_step_count(arr, tolerance=0.000001):\n",
    "        arr_len = len(arr[0])\n",
    "        not_done = True\n",
    "        step = 0\n",
    "        while not_done:\n",
    "            for c in range(arr_len):      \n",
    "                error = False\n",
    "                column = arr[:, c]\n",
    "                col_avg = np.sum(column)/arr_len\n",
    "                for entry in column:\n",
    "                    if np.abs(entry- col_avg) >= tolerance:  \n",
    "                        error = True \n",
    "                        break\n",
    "                if error: \n",
    "                    break    \n",
    "            else:\n",
    "                not_done = False \n",
    "                \n",
    "            if not_done:         \n",
    "                arr = np.matmul(arr, arr) \n",
    "                step += 1\n",
    "                \n",
    "        return step\n",
    "    \n",
    "    for n, file_name in enumerate(file_names):\n",
    "        steps[f\"Dataset {n+1}\"] = method_matrix_multiplication_step_count(pull_file(file_name))\n",
    "        \n",
    "    return steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"2\" halign=\"left\">Dataset 1</th>\n",
       "      <th colspan=\"2\" halign=\"left\">Dataset 2</th>\n",
       "      <th colspan=\"2\" halign=\"left\">Dataset 3</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>MSE</th>\n",
       "      <th>Runtime (s)</th>\n",
       "      <th>MSE</th>\n",
       "      <th>Runtime (s)</th>\n",
       "      <th>MSE</th>\n",
       "      <th>Runtime (s)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Method 1</th>\n",
       "      <td>-</td>\n",
       "      <td>0.001040</td>\n",
       "      <td>-</td>\n",
       "      <td>0.067954</td>\n",
       "      <td>-</td>\n",
       "      <td>7.901031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Method 2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>16.286761</td>\n",
       "      <td>0.0</td>\n",
       "      <td>74.319093</td>\n",
       "      <td>0.0</td>\n",
       "      <td>680.653591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Method 3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.002049</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.092203</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.429134</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Dataset 1             Dataset 2             Dataset 3            \n",
       "               MSE Runtime (s)       MSE Runtime (s)       MSE Runtime (s)\n",
       "Method 1         -    0.001040         -    0.067954         -    7.901031\n",
       "Method 2       0.0   16.286761       0.0   74.319093       0.0  680.653591\n",
       "Method 3       0.0    0.002049       0.0    0.092203       0.0    8.429134"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Output the data frame\n",
    "\n",
    "create_dataframe(file_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "My expectations and results are coincide, it was clear that mean square error is near zero since matrix multiplication has the sensivity of 0.000001 and simulation runs for a million step. Those are the reasons that functions output such a clean steady states that are almost exactly as the same output of analytical solution. However the exact MSE's are not zero as the data frame shows but a value is so small in the order of e^-7 that rounds to zero. Method 2 and Method 3 are both reliable but it depends on the tolerance of the method 3 and how many simulations will be executed by the method 2. One can make them very reliable by making their precision higher but if I were to choose a more reliable method, I would choose method 3 from 2 and 3 because of the cost of precision comes as runtime and this brings us to examination of the runtimes. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It can be easily seen that simulation method is by far the most time consuming method of them all since it simulates all the steps until it executes for a million time. Method Matrix Multiplication and Method Analtyic Solution is very close for the lenght of runtimes but since Analtyic Solution directly calculates the eigenvalues and eigenvectors, it comes out victorius because of the Method Matrix Multiplication has to do great number of multiplications even tough the number of multiplications is very low. Let us examine the number of steps required for the method 3 by introducing a new function.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Dataset 1': 4, 'Dataset 2': 3, 'Dataset 3': 2}"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Returns a dictionary of number of steps that are executed for each dataset\n",
    "\n",
    "number_of_iterations_of_method_3(file_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It can be seen that number of iterations may differ for each dataset even though number of iterations may be small, the required number of calculations are exponentially geting bigger that is the reason why runtime expands."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "# An absorbing state is added to dataset 1\n",
    "\n",
    "arr_absorbing = create_absorbing_state(pull_file(file_names[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "[9.99995e-01 0.00000e+00 2.00000e-06 0.00000e+00 0.00000e+00 1.00000e-06\n",
      " 1.00000e-06 0.00000e+00 0.00000e+00 1.00000e-06]\n",
      "[1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "for sol in check_absorbing_state(arr_absorbing):\n",
    "    print(sol)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Steady state solutions show that in the long run markov chain is always on the state 0 since it become an absorbing state.\n",
    "\n",
    "Note: The steady states of datasets can be rounded to [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
